# ğŸ“Š Proyecto de AnÃ¡lisis de Sentimientos de Tweets con un modelo de ClasificaciÃ³n.

## ğŸ¯ Problema de Negocio

El objetivo de este proyecto es analizar los sentimientos de los tweets, identificando si los mensajes son positivos o negativos. Utilizando un conjunto de datos de 1,600,000 tweets preprocesados, se pretende generar diversas caracterÃ­sticas que se utilizarÃ¡n para entrenar un modelo de clasificaciÃ³n.

## â“ Preguntas Clave

- ğŸ“ˆ **Â¿QuÃ© tan efectivos son los anÃ¡lisis de sentimientos aplicados sobre datos textuales como los tweets?**
- ğŸ”„ **Â¿QuÃ© transformaciones y caracterÃ­sticas textuales son relevantes para mejorar la predicciÃ³n de sentimientos?**
- ğŸ˜ **Â¿CÃ³mo podemos detectar sarcasmo en tweets utilizando tÃ©cnicas de anÃ¡lisis de sentimientos?**
- ğŸ§® **Â¿QuÃ© mÃ©tricas se pueden utilizar para evaluar el desempeÃ±o del modelo?**

## ğŸš€ ConfiguraciÃ³n del Ambiente

AsegÃºrate de tener instaladas las siguientes bibliotecas necesarias para la ejecuciÃ³n del cÃ³digo:

```bash
pip install nltk
pip install emoji
pip install vaderSentiment
pip install textblob
```

### Otras librerÃ­as requeridas:

- pandas
- re (Regular Expressions)
- string
- matplotlib
- seaborn
- sklearn

```bash
pip install numpy pandas seaborn matplotlib scikit-learn
```

## ğŸ—„ï¸ ObtenciÃ³n y Tratamiento de Datos

### Cargando la Base de Datos

El conjunto de datos proviene de un archivo CSV llamado `training_1600000_processed_noemoticon.csv`, que contiene 1,600,000 tweets junto con su anotaciÃ³n de sentimiento (0 = negativo, 4 = positivo).

```python
df = pd.read_csv("training_1600000_processed_noemoticon.csv", encoding='latin-1')
df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']
```

### Tratamiento de Datos

Durante el preprocesamiento se realizan las siguientes operaciones clave:

- ğŸ§¹ **EliminaciÃ³n de URLs, menciones y emojis**: Se remueven del texto ya que pueden agregar ruido al anÃ¡lisis.
- âŒ **EliminaciÃ³n de signos de puntuaciÃ³n y caracteres especiales**: Para normalizar el texto antes de aplicar las transformaciones.
- ğŸ”¡ **TransformaciÃ³n a minÃºsculas**: Para evitar que las palabras en mayÃºsculas se traten como diferentes palabras.
- ğŸ› ï¸ **GeneraciÃ³n de caracterÃ­sticas adicionales**: Se generan nuevas variables basadas en el texto, como longitud del tweet, conteo de stopwords, densidad de palabras en mayÃºsculas, entre otras.

## ğŸ“ GeneraciÃ³n de CaracterÃ­sticas

Se generaron varias caracterÃ­sticas a partir del texto de los tweets. Estas incluyen:

1. **Longitud del tweet** (`tweet_length`).
2. **Conteo de emojis** (`emoji_count`).
3. **Conteo de signos de exclamaciÃ³n/interrogaciÃ³n** (`exclamation_count`, `question_count`).
4. **Densidad de palabras en mayÃºsculas** (`capital_word_density`).
5. **Conteo de palabras** (`word_count`).
6. **Conteo de stopwords** (`stopword_count`).
7. **Conteo de palabras Ãºnicas** (`unique_word_count`).
8. **ProporciÃ³n de palabras repetidas** (`repeated_word_proportion`).
10. **Subjetividad del sentimiento usando TextBlob** (`textblob_subjectivity`).
11. **Conteo de signos de puntuaciÃ³n** (`punctuation_count`).
12. **Conteo de menciones y hashtags** (`mention_count`, `hashtag_count`).
13. **EntropÃ­a del texto** (`text_entropy`).
14. **DetecciÃ³n de sarcasmo** usando VADER y anÃ¡lisis del texto (`sarcasm`).


## ğŸ”€ DivisiÃ³n de los Datos

El dataset fue dividido en conjuntos de entrenamiento, validaciÃ³n y prueba usando una proporciÃ³n de 70% para entrenamiento, 15% para validaciÃ³n y 15% para prueba.

```python
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)
```

## ğŸ“Š VisualizaciÃ³n

Se generÃ³ una visualizaciÃ³n que muestra la distribuciÃ³n de las clases (sentimientos) en el conjunto de datos de entrenamiento.

```python
# Crear una figura de tamaÃ±o adecuado
plt.figure(figsize=(10, 6))

# GrÃ¡fico de barras para ver la distribuciÃ³n del target
ax = sns.countplot(data=df, x='target', palette="pastel", order=sorted(df['target'].unique()))

# Mostrar el grÃ¡fico
plt.show()
```

## ğŸ§  Modelado

Se dividiÃ³ el conjunto de datos en conjuntos de **entrenamiento**, **prueba** y **validaciÃ³n**, y luego se entrenaron modelos de machine learning (Xgboost y lightgbm) utilizando las caracterÃ­sticas generadas a partir de los textos procesados.

## ğŸ“ˆ EvaluaciÃ³n del Modelo

Finalmente, se evaluÃ³ el modelo utilizando mÃ©tricas de clasificaciÃ³n como **Auc**, **accuracy**, **precision**, **recall**, **F1-score**. AdemÃ¡s, se realizaron ajustes adicionales de hiperparÃ¡metros mediante tÃ©cnicas como GridSearchCV y validaciÃ³n cruzada.

## ğŸ Conclusiones

Este proyecto utiliza tÃ©cnicas avanzadas de preprocesamiento de texto para crear un modelo capaz de predecir el sentimiento de tweets y detectar sarcasmo en ellos. El modelo resultante puede ser mejorado con tÃ©cnicas adicionales de NLP y ajustando los hiperparÃ¡metros segÃºn los resultados obtenidos.
