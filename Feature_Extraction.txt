import pandas as pd
import re
import string
import emoji
from nltk.corpus import stopwords
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# Preprocesar el texto eliminando URLs, menciones, emojis y caracteres especiales
def clean_text(text):
    # Eliminar URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    # Eliminar menciones de usuarios (@)
    text = re.sub(r'\@\w+', '', text)
    # Eliminar emojis
    text = emoji.replace_emoji(text, replace="")
    # Eliminar signos de puntuación y números
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Convertir a minúsculas
    text = text.lower()
    return text

df = pd.read_csv("training_1600000_processed_noemoticon.csv", encoding='latin-1')
df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']

df['cleaned_text'] = df['text'].apply(clean_text)

import nltk
import math
from textblob import TextBlob

df = df[['target', 'text','date', 'cleaned_text']]
# C) Longitud del tweet (número de caracteres)
df['tweet_length'] = df['cleaned_text'].apply(len)
# D) Frecuencia de emojis
def count_emojis(text):
    return sum(1 for char in text if char in emoji.EMOJI_DATA)

df['emoji_count'] = df['text'].apply(count_emojis)
# E) Uso de signos de exclamación/interrogación
df['exclamation_count'] = df['text'].apply(lambda x: x.count('!'))
df['question_count'] = df['text'].apply(lambda x: x.count('?'))

# Función para calcular la proporción de palabras en mayúsculas en un tweet
def capital_word_density(text):
    words = text.split()
    if len(words) == 0:
        return 0
    uppercase_words = [word for word in words if word.isupper()]
    return len(uppercase_words) / len(words)

df['capital_word_density'] = df['text'].apply(capital_word_density)
# Calcular la cantidad de palabras en cada tweet
df['word_count'] = df['cleaned_text'].apply(lambda x: len(x.split()))

# Contar el número de stopwords en cada tweet
stop_words = set(stopwords.words('english'))

def stopword_count(text):
    words = text.split()
    stopword_count = sum(1 for word in words if word in stop_words)
    return stopword_count

df['stopword_count'] = df['cleaned_text'].apply(stopword_count)
# Función para contar el número de palabras únicas en cada tweet
df['unique_word_count'] = df['cleaned_text'].apply(lambda x: len(set(x.split())))
# Calcular la proporción de palabras repetidas
def repeated_word_proportion(text):
    words = text.split()
    if len(words) == 0:
        return 0
    unique_words = set(words)
    return (len(words) - len(unique_words)) / len(words)

df['repeated_word_proportion'] = df['cleaned_text'].apply(repeated_word_proportion)

# Sentimiento global usando TextBlob
df['textblob_polarity'] = df['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)
df['textblob_subjectivity'] = df['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)
# Contar la cantidad de signos de puntuación
df['punctuation_count'] = df['text'].apply(lambda x: len([char for char in x if char in string.punctuation]))
# Contar el número de menciones y hashtags
df['mention_count'] = df['text'].apply(lambda x: x.count('@'))
df['hashtag_count'] = df['text'].apply(lambda x: x.count('#'))

def calculate_entropy(text):
    prob = [text.count(c) / len(text) for c in set(text)]
    entropy = -sum([p * math.log(p) for p in prob])
    return entropy

df['text_entropy'] = df['cleaned_text'].apply(calculate_entropy)
# Función para detectar sarcasmo basado en el uso de exclamaciones y puntuaciones
def detect_sarcasm(text):
    if '!' in text and analyzer.polarity_scores(text)['neg'] > 0.5:
        return 1
    return 0

df['sarcasm'] = df['text'].apply(detect_sarcasm)

df.to_csv('datatotal.csv')